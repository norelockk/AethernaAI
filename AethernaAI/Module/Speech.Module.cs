using Microsoft.CognitiveServices.Speech;
using Microsoft.CognitiveServices.Speech.Audio;
using AethernaAI.Enum;
using AethernaAI.Util;
using NAudio.CoreAudioApi;
using System.Collections.Concurrent;

namespace AethernaAI.Module;

public class SpeechModule : IDisposable
{
    private readonly Core _core;
    private SpeechRecognizer? _recognizer;
    private SpeechConfig? _config;
    private AudioConfig? _audioConfig;
    private RecognizeLang _currentLanguage;
    private readonly ConcurrentQueue<string> _recognitionQueue = new();
    private readonly CancellationTokenSource _cancellationTokenSource = new();
    private readonly System.Timers.Timer _healthCheckTimer;
    private readonly object _reconnectLock = new();
    private bool _isDisposed;
    private bool _needsReconnect;
    private DateTime _lastRecognitionTime = DateTime.Now;
    private int _reconnectAttempts;

    // Quota management
    private const int QUOTA_PAUSE_MS = 60000; // 1 minute pause
    private DateTime _quotaResetTime = DateTime.MinValue;
    private System.Timers.Timer? _quotaTimer;
    private TaskCompletionSource<bool>? _quotaResetTask;
    private bool _isInQuotaPause;

    // Constants
    private const int HEALTH_CHECK_INTERVAL_MS = 30000;
    private const int RECOGNITION_TIMEOUT_MS = 60000;
    private const int RECONNECT_DELAY_MS = 5000;
    private const int MAX_RECONNECT_ATTEMPTS = 5;

    public bool IsListening { get; private set; }
    public event EventHandler<string>? OnSpeechRecognized;
    public event EventHandler<ConnectionStatus>? OnConnectionStatusChanged;

    public enum ConnectionStatus
    {
        Connected,
        Disconnected,
        Reconnecting,
        Failed,
        QuotaExceeded
    }

    public SpeechModule(Core core)
    {
        _core = core ?? throw new ArgumentNullException(nameof(core));
        _healthCheckTimer = new System.Timers.Timer(HEALTH_CHECK_INTERVAL_MS);
        _healthCheckTimer.Elapsed += async (s, e) => await CheckConnectionHealthAsync();
        Initialize();
        StartHealthCheck();
        Logger.Log(LogLevel.Info, "Speech module initialized");
    }

    private void Initialize()
    {
        try
        {
            if (_isInQuotaPause)
            {
                Logger.Log(LogLevel.Info, "Skipping initialization during quota pause");
                return;
            }

            _currentLanguage = _core.Config.GetConfig<RecognizeLang>(config => config.SpeechRecognizerLanguage);
            var token = _core.Config.GetConfig<string?>(config => config.SpeechRecognizerToken!);
            var region = _core.Config.GetConfig<string?>(config => config.SpeechRecognizerRegion!);

            if (string.IsNullOrEmpty(token) || string.IsNullOrEmpty(region))
            {
                throw new ArgumentNullException("Speech configuration is missing required values");
            }

            InitializeSpeechComponents(token, region);
            SetupRecognizer();
        }
        catch (Exception ex)
        {
            Logger.Log(LogLevel.Error, $"Failed to initialize Speech module: {ex.Message}");
            throw;
        }
    }

    private void InitializeSpeechComponents(string token, string region)
    {
        _config = SpeechConfig.FromSubscription(token, region);
        _config.SetProfanity(ProfanityOption.Raw);
        _config.SpeechRecognitionLanguage = GetLanguageCode(_currentLanguage);

        // Connection settings
        _config.SetProperty("SpeechServiceConnection_ReconnectOnError", "false");
        _config.SetProperty("SpeechServiceConnection_InitialSilenceTimeoutMs", "15000");
        _config.SetProperty("SpeechServiceConnection_EndSilenceTimeoutMs", "15000");
        _config.SetProperty("SpeechServiceConnection_MaxRetryCount", "0");

        // Noise suppression settings
        _config.SetProperty("SpeechServiceConnection_NoiseSuppression", "true");
        _config.SetProperty("SpeechServiceConnection_NoiseSuppressionLevel", "High");
        
        // Speech detection settings
        _config.SetProperty("SpeechServiceConnection_VadMode", "Low");
        _config.SetProperty("SpeechServiceConnection_AutoDetectSourceLanguage", "false");
        _config.SetProperty("SpeechServiceConnection_TransmitLengthBeforeThreshold", "100");
        
        // Recognition thresholds
        _config.SetProperty("SpeechServiceConnection_SpeechDetectionThreshold", "0.5");
        _config.SetProperty("SpeechServiceConnection_SpeechSegmentationSilenceTimeoutMs", "300");

        _audioConfig = GetAudioConfig();
    }

    private void SetupRecognizer()
    {
        _recognizer?.Dispose();
        _recognizer = new SpeechRecognizer(_config, _audioConfig);

        _recognizer.Recognized += OnRecognized;
        _recognizer.Canceled += OnCanceled;
        _recognizer.SessionStarted += (s, e) =>
        {
            _reconnectAttempts = 0;
            OnConnectionStatusChanged?.Invoke(this, ConnectionStatus.Connected);
            Logger.Log(LogLevel.Info, "Speech recognition session started");
        };
        _recognizer.SessionStopped += (s, e) =>
        {
            if (!_isDisposed && IsListening && !_isInQuotaPause)
            {
                _needsReconnect = true;
            }
        };
    }

    private AudioConfig GetAudioConfig()
    {
        try
        {
            var enumerator = new MMDeviceEnumerator();
            var devices = enumerator.EnumerateAudioEndPoints(DataFlow.Capture, DeviceState.Active);
            var targetDevice = devices.FirstOrDefault(d =>
                d.FriendlyName.Contains("Virtual Cable", StringComparison.OrdinalIgnoreCase));

            return AudioConfig.FromDefaultMicrophoneInput();
        }
        catch (Exception ex)
        {
            Logger.Log(LogLevel.Error, $"Failed to initialize audio config: {ex.Message}");
            throw;
        }
    }

    private string GetLanguageCode(RecognizeLang lang) => lang switch
    {
        RecognizeLang.Polish => "pl-PL",
        RecognizeLang.English => "en-US",
        _ => "en-US"
    };

    private void StartHealthCheck()
    {
        _healthCheckTimer.Start();
    }

    private async Task HandleQuotaExceeded()
    {
        lock (_reconnectLock)
        {
            if (_isInQuotaPause)
            {
                return; // Already handling quota pause
            }
            _isInQuotaPause = true;
        }

        try
        {
            OnConnectionStatusChanged?.Invoke(this, ConnectionStatus.QuotaExceeded);
            Logger.Log(LogLevel.Warn, "Quota exceeded, pausing speech recognition for 1 minute");
            
            await StopListeningAsync();

            _quotaResetTask = new TaskCompletionSource<bool>();
            _quotaTimer = new System.Timers.Timer(QUOTA_PAUSE_MS);
            
            _quotaTimer.Elapsed += async (s, e) =>
            {
                _quotaTimer.Stop();
                _quotaTimer.Dispose();
                _isInQuotaPause = false;
                _quotaResetTask?.TrySetResult(true);
                
                try
                {
                    Initialize();
                    await StartListeningAsync();
                    OnConnectionStatusChanged?.Invoke(this, ConnectionStatus.Connected);
                }
                catch (Exception ex)
                {
                    Logger.Log(LogLevel.Error, $"Failed to resume after quota pause: {ex.Message}");
                }
            };

            _quotaTimer.Start();
            _quotaResetTime = DateTime.Now.AddMilliseconds(QUOTA_PAUSE_MS);

            // Wait for the quota timer to complete
            await _quotaResetTask.Task;
        }
        catch (Exception ex)
        {
            Logger.Log(LogLevel.Error, $"Error in quota handling: {ex.Message}");
            _isInQuotaPause = false;
        }
    }

    private async Task CheckConnectionHealthAsync()
    {
        if (!IsListening || _isDisposed || _isInQuotaPause) return;

        var timeSinceLastRecognition = DateTime.Now - _lastRecognitionTime;
        if (timeSinceLastRecognition.TotalMilliseconds > RECOGNITION_TIMEOUT_MS)
        {
            Logger.Log(LogLevel.Warn, "No recognition events detected for a while, attempting reconnection");
            _needsReconnect = true;
            await ReconnectAsync();
        }
    }

    private async Task ReconnectAsync()
    {
        if (_isInQuotaPause)
        {
            Logger.Log(LogLevel.Debug, "Skipping reconnection during quota pause");
            return;
        }

        if (DateTime.Now < _quotaResetTime)
        {
            Logger.Log(LogLevel.Debug, "Still in quota pause period, skipping reconnection");
            return;
        }

        lock (_reconnectLock)
        {
            if (!_needsReconnect || _isDisposed) return;
            if (_reconnectAttempts >= MAX_RECONNECT_ATTEMPTS)
            {
                OnConnectionStatusChanged?.Invoke(this, ConnectionStatus.Failed);
                Logger.Log(LogLevel.Error, "Max reconnection attempts reached");
                return;
            }
        }

        try
        {
            _reconnectAttempts++;
            OnConnectionStatusChanged?.Invoke(this, ConnectionStatus.Reconnecting);
            Logger.Log(LogLevel.Info, $"Attempting reconnection (attempt {_reconnectAttempts}/{MAX_RECONNECT_ATTEMPTS})");

            await StopListeningAsync();
            await Task.Delay(RECONNECT_DELAY_MS);
            Initialize();
            await StartListeningAsync();

            _needsReconnect = false;
            OnConnectionStatusChanged?.Invoke(this, ConnectionStatus.Connected);
        }
        catch (Exception ex)
        {
            Logger.Log(LogLevel.Error, $"Reconnection attempt failed: {ex.Message}");
            if (_reconnectAttempts < MAX_RECONNECT_ATTEMPTS)
            {
                await Task.Delay(RECONNECT_DELAY_MS);
                await ReconnectAsync();
            }
        }
    }

    private void OnRecognized(object? sender, SpeechRecognitionEventArgs e)
    {
        _lastRecognitionTime = DateTime.Now;

        if (e.Result.Reason == ResultReason.RecognizedSpeech)
        {
            var recognizedText = e.Result.Text.Trim();
            
            if (ShouldFilterOut(recognizedText))
            {
                Logger.Log(LogLevel.Debug, $"Filtered out noise: {recognizedText}");
                return;
            }

            ProcessRecognizedSpeech(recognizedText);
        }
    }

    private bool ShouldFilterOut(string text)
    {
        if (string.IsNullOrWhiteSpace(text)) return true;

        var cleanText = text.Trim().ToLower();
        if (cleanText.Length <= 1) return true;

        string[] noisePatterns = { 
            "hmm", "uhh", "ahh", "eh", "um", "uh",
            "tsk", "pfff", "shh", "ssh", "psst",
            "click", "tick", "knock", "tap", "*",
            ".", ",", "!", "?", "-"
        };

        if (noisePatterns.Contains(cleanText)) return true;
        return !cleanText.Any(char.IsLetter);
    }

    private void ProcessRecognizedSpeech(string recognizedText)
    {
        try
        {
            _recognitionQueue.Enqueue(recognizedText);
            Logger.Log(LogLevel.Debug, $"Speech recognized: {recognizedText}");
            OnSpeechRecognized?.Invoke(this, recognizedText);
            _core.Bus.Emit("SpeechRecognized", recognizedText);
        }
        catch (Exception ex)
        {
            Logger.Log(LogLevel.Error, $"Failed to process recognized speech: {ex.Message}");
        }
    }

    private async void OnCanceled(object? sender, SpeechRecognitionCanceledEventArgs e)
    {
        if (e.Reason == CancellationReason.Error)
        {
            if (e.ErrorDetails.Contains("Quota exceeded"))
            {
                Logger.Log(LogLevel.Error, $"Speech recognition canceled due to quota: {e.ErrorDetails}");
                await HandleQuotaExceeded();
            }
            else 
            {
                Logger.Log(LogLevel.Error, $"Speech recognition canceled: {e.ErrorCode} - {e.ErrorDetails}");
                _needsReconnect = true;
                await ReconnectAsync();
            }
        }
    }

    public async Task StartListeningAsync()
    {
        if (!IsListening && !_isDisposed && _recognizer != null && !_isInQuotaPause)
        {
            try
            {
                IsListening = true;
                await _recognizer.StartContinuousRecognitionAsync();
                _lastRecognitionTime = DateTime.Now;
                Logger.Log(LogLevel.Info, "Speech recognition started");
            }
            catch (Exception ex)
            {
                IsListening = false;
                Logger.Log(LogLevel.Error, $"Failed to start listening: {ex.Message}");
                throw;
            }
        }
    }

    public async Task StopListeningAsync()
    {
        if (IsListening && !_isDisposed && _recognizer != null)
        {
            try
            {
                IsListening = false;
                await _recognizer.StopContinuousRecognitionAsync();
                Logger.Log(LogLevel.Info, "Speech recognition stopped");
            }
            catch (Exception ex)
            {
                Logger.Log(LogLevel.Error, $"Error stopping speech recognition: {ex.Message}");
                throw;
            }
        }
    }

    public async Task SetLanguageAsync(RecognizeLang language)
    {
        if (_currentLanguage != language && !_isInQuotaPause)
        {
            try
            {
                _currentLanguage = language;
                await StopListeningAsync();
                Initialize();
                if (IsListening)
                {
                    await StartListeningAsync();
                }
                Logger.Log(LogLevel.Info, $"Speech recognition language changed to {language}");
            }
            catch (Exception ex)
            {
                Logger.Log(LogLevel.Error, $"Failed to change language: {ex.Message}");
                throw;
            }
        }
    }

    public void Dispose()
    {
        Dispose(true);
        GC.SuppressFinalize(this);
    }

    protected virtual void Dispose(bool disposing)
    {
        if (!_isDisposed)
        {
            if (disposing)
            {
                _healthCheckTimer.Stop();
                _healthCheckTimer.Dispose();
                _cancellationTokenSource.Cancel();
                _quotaTimer?.Stop();
                _quotaTimer?.Dispose();
                _recognizer?.Dispose();
                _audioConfig?.Dispose();
            }
            _isDisposed = true;
        }
    }

    ~SpeechModule()
    {
        Dispose(false);
    }
}